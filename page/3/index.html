<!DOCTYPE html><html class="hide-aside" lang="en" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>ReadingNotes - Temporary Reading Notes</title><meta name="author"><meta name="copyright"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="Temporary reading notes and testing the Hexo framework. Not for public use.">
<meta property="og:type" content="website">
<meta property="og:title" content="ReadingNotes">
<meta property="og:url" content="https://bzhao2718.github.io/reading-notes/page/3/index.html">
<meta property="og:site_name" content="ReadingNotes">
<meta property="og:description" content="Temporary reading notes and testing the Hexo framework. Not for public use.">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://i.loli.net/2021/02/24/5O1day2nriDzjSu.png">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://i.loli.net/2021/02/24/5O1day2nriDzjSu.png"><link rel="shortcut icon" href="/reading-notes/img/favicon.png"><link rel="canonical" href="https://bzhao2718.github.io/reading-notes/page/3/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="stylesheet" href="/reading-notes/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/reading-notes/',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"We didn't find any results for the search: ${query}"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":500},
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: 'Just',
    min: 'minutes ago',
    hour: 'hours ago',
    day: 'days ago',
    month: 'months ago'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    jQuery: 'https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js',
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
    },
    fancybox: {
      js: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js',
      css: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css'
    }
  },
  isPhotoFigcaption: true,
  islazyload: true,
  isanchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'ReadingNotes',
  isPost: false,
  isHome: true,
  isHighlightShrink: false,
  isToc: false,
  postUpdate: '2022-06-21 12:00:03'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const fontSizeVal = saveToLocal.get('global-font-size')
    if (fontSizeVal !== undefined) {
      document.documentElement.style.setProperty('--global-font-size', fontSizeVal + 'px')
    }
    
    const detectApple = () => {
      if (GLOBAL_CONFIG_SITE.isHome && /iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><!-- hexo injector head_end start --><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/l-lin/font-awesome-animation/dist/font-awesome-animation.min.css" media="defer" onload="this.media='all'"><link rel="stylesheet" href="https://unpkg.zhimg.com/hexo-butterfly-tag-plugins-plus@latest/lib/tag_plugins.css" media="defer" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/hexo-butterfly-tag-plugins-plus@latest/lib/carousel-touch.min.js"></script><!-- hexo injector head_end end --><meta name="generator" content="Hexo 6.2.0"><style>mjx-container[jax="SVG"] {
  direction: ltr;
}

mjx-container[jax="SVG"] > svg {
  overflow: visible;
}

mjx-container[jax="SVG"][display="true"] {
  display: block;
  text-align: center;
  margin: 1em 0;
}

mjx-container[jax="SVG"][justify="left"] {
  text-align: left;
}

mjx-container[jax="SVG"][justify="right"] {
  text-align: right;
}

g[data-mml-node="merror"] > g {
  fill: red;
  stroke: red;
}

g[data-mml-node="merror"] > rect[data-background] {
  fill: yellow;
  stroke: none;
}

g[data-mml-node="mtable"] > line[data-line] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > rect[data-frame] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > .mjx-dashed {
  stroke-dasharray: 140;
}

g[data-mml-node="mtable"] > .mjx-dotted {
  stroke-linecap: round;
  stroke-dasharray: 0,140;
}

g[data-mml-node="mtable"] > svg {
  overflow: visible;
}

[jax="SVG"] mjx-tool {
  display: inline-block;
  position: relative;
  width: 0;
  height: 0;
}

[jax="SVG"] mjx-tool > mjx-tip {
  position: absolute;
  top: 0;
  left: 0;
}

mjx-tool > mjx-tip {
  display: inline-block;
  padding: .2em;
  border: 1px solid #888;
  font-size: 70%;
  background-color: #F8F8F8;
  color: black;
  box-shadow: 2px 2px 5px #AAAAAA;
}

g[data-mml-node="maction"][data-toggle] {
  cursor: pointer;
}

mjx-status {
  display: block;
  position: fixed;
  left: 1em;
  bottom: 1em;
  min-width: 25%;
  padding: .2em .4em;
  border: 1px solid #888;
  font-size: 90%;
  background-color: #F8F8F8;
  color: black;
}

foreignObject[data-mjx-xml] {
  font-family: initial;
  line-height: normal;
  overflow: visible;
}

.MathJax path {
  stroke-width: 3;
}

mjx-container[display="true"] {
  overflow: auto hidden;
}

mjx-container[display="true"] + br {
  display: none;
}
</style></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src= "data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" data-lazy-src="https://i.loli.net/2021/02/24/5O1day2nriDzjSu.png" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data"><div class="data-item is-center"><div class="data-item-link"><a href="/reading-notes/archives/"><div class="headline">Articles</div><div class="length-num">102</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/reading-notes/tags/"><div class="headline">Tags</div><div class="length-num">22</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/reading-notes/categories/"><div class="headline">Categories</div><div class="length-num">12</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/reading-notes/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/reading-notes/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/reading-notes/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/reading-notes/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/reading-notes/link/"><i class="fa-fw fas fa-link"></i><span> Link</span></a></div><div class="menus_item"><a class="site-page" href="/reading-notes/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div></div></div><div class="page" id="body-wrap"><header class="not-top-img" id="page-header"><nav id="nav"><span id="blog_name"><a id="site-name" href="/reading-notes/">ReadingNotes</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> Search</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/reading-notes/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/reading-notes/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/reading-notes/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/reading-notes/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/reading-notes/link/"><i class="fa-fw fas fa-link"></i><span> Link</span></a></div><div class="menus_item"><a class="site-page" href="/reading-notes/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav></header><main class="layout" id="content-inner"><div class="recent-posts" id="recent-posts"><div class="recent-post-item"><div class="post_cover left_radius"><a href="/reading-notes/cqNotes/ML/cq_ml_math/" title="cq_ml_math">     <img class="post_bg" src= "data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" data-lazy-src="/reading-notes/default_cover/museum-5431661_1280.jpg" onerror="this.onerror=null;this.src='/reading-notes/img/404.jpg'" alt="cq_ml_math"></a></div><div class="recent-post-info"><a class="article-title" href="/reading-notes/cqNotes/ML/cq_ml_math/" title="cq_ml_math">cq_ml_math</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time datetime="2021-01-01T03:53:22.000Z" title="Created 2021-01-01 11:53:22">2021-01-01</time></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/reading-notes/tags/ml-math/">ml_math</a><span class="article-meta__link">•</span><a class="article-meta__tags" href="/reading-notes/tags/calculus/">calculus</a></span></div><div class="content">Calculus
Partial Derivatives
See this note: Partial
Derivatives pdf
Vector Basics
See this note: Vector
Basics1 (Use Word to open, it seems that it’s not showing some
symbols using Devonthink).
Vector Functions And
Derivatives
See this note Vector
Valued Function.
Jacobian Matrix
See this note: LectureNotes12PartialDerivatives
for detail of vector-valued function and Jocobian matrix.
Definition 1
Let’s call y the output vector of f. The
Jacobian matrix of f contains the partial derivatives of ea ...</div></div></div><div class="recent-post-item"><div class="post_cover right_radius"><a href="/reading-notes/cqNotes/cq_software_dev/" title="cq_software_temp_notes">     <img class="post_bg" src= "data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" data-lazy-src="/reading-notes/default_cover/trees-6207925_1920.jpg" onerror="this.onerror=null;this.src='/reading-notes/img/404.jpg'" alt="cq_software_temp_notes"></a></div><div class="recent-post-info"><a class="article-title" href="/reading-notes/cqNotes/cq_software_dev/" title="cq_software_temp_notes">cq_software_temp_notes</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time datetime="2020-12-31T16:00:00.000Z" title="Created 2021-01-01 00:00:00">2021-01-01</time></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/reading-notes/tags/software-dev/">software_dev</a><span class="article-meta__link">•</span><a class="article-meta__tags" href="/reading-notes/tags/java/">java</a></span></div><div class="content">Spring
Messaging Queue
Synchronous communication, which is what we’ve seen with REST, has
its place. But it’s not the only style of inter-application
communication available to developers. Asynchronous messaging is a way
of indirectly sending messages from one application to another without
waiting for a response. This indirection affords looser coupling and
greater scalability between the communicating applications.
JMS
JMS is a Java standard that defines a common API for working with
message b ...</div></div></div><div class="recent-post-item"><div class="post_cover left_radius"><a href="/reading-notes/cqNotes/InfoTheory/rc_infot_Entropy%20in%20Data%20Science/" title="rc_info_entropy">     <img class="post_bg" src= "data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" data-lazy-src="/reading-notes/default_cover/reading-7229927_1280.jpg" onerror="this.onerror=null;this.src='/reading-notes/img/404.jpg'" alt="rc_info_entropy"></a></div><div class="recent-post-info"><a class="article-title" href="/reading-notes/cqNotes/InfoTheory/rc_infot_Entropy%20in%20Data%20Science/" title="rc_info_entropy">rc_info_entropy</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time datetime="2020-12-31T16:00:00.000Z" title="Created 2021-01-01 00:00:00">2021-01-01</time></span></div><div class="content">Information Theory Concept:
Entropy
From
Entropy
– A Key Concept for All Data Science Beginners
Information theory is a mathematical approach to the
study of coding of information along with the quantification, storage,
and communication of information.”*
In his paper, he had set out to mathematically measure the
statistical nature of “lost information” in phone-line signals. The work
was aimed at the problem of how best to encode the information a sender
wants to transmit. For this purpose, inf ...</div></div></div><div class="recent-post-item"><div class="post_cover right_radius"><a href="/reading-notes/cqNotes/Java/cq_java_note1/" title="cq_java_temp_note">     <img class="post_bg" src= "data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" data-lazy-src="/reading-notes/default_cover/rainbow-5324147_1280.jpg" onerror="this.onerror=null;this.src='/reading-notes/img/404.jpg'" alt="cq_java_temp_note"></a></div><div class="recent-post-info"><a class="article-title" href="/reading-notes/cqNotes/Java/cq_java_note1/" title="cq_java_temp_note">cq_java_temp_note</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time datetime="2020-12-31T16:00:00.000Z" title="Created 2021-01-01 00:00:00">2021-01-01</time></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/reading-notes/tags/software-dev/">software_dev</a><span class="article-meta__link">•</span><a class="article-meta__tags" href="/reading-notes/tags/java/">java</a></span></div><div class="content">



The map method returns a new stream by mapping each element in the
stream into a new element. So, the map method in line 42 returns a new
stream with all uppercase strings. The distinct() method obtains a new
stream with all distinct elements. The count() method counts the number
of the elements in the stream. So, the stream pipeline in line 43 counts
the number of distinct strings in the array names.

Use peek() to see the element in the stream or modify each element in
the stream.
Java 8
S ...</div></div></div><div class="recent-post-item"><div class="post_cover left_radius"><a href="/reading-notes/cqNotes/DataScience/cq_bias_variance_fitting/" title="cq_bias_variance_fitting">     <img class="post_bg" src= "data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" data-lazy-src="/reading-notes/default_cover/monk-6113501_1920.png" onerror="this.onerror=null;this.src='/reading-notes/img/404.jpg'" alt="cq_bias_variance_fitting"></a></div><div class="recent-post-info"><a class="article-title" href="/reading-notes/cqNotes/DataScience/cq_bias_variance_fitting/" title="cq_bias_variance_fitting">cq_bias_variance_fitting</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time datetime="2020-12-31T16:00:00.000Z" title="Created 2021-01-01 00:00:00">2021-01-01</time></span></div><div class="content">The Bias and Variance
Intro to Statistical
Learning

Left: Data simulated from ,
shown in black. Three estimates of ​ Are shown: the linear regression line
(orange curve), and two shooting spline fits (blue and green curves).
Right: Training MSE (grey curve), test MSE (red curve), and minimum
possible test MSE over all methods (dashed line). Squares represent the
training and test MSEs for the three fits shown in the left-hand
panel.
It is possible to show that the expected test MSE, for a given ...</div></div></div><div class="recent-post-item"><div class="post_cover right_radius"><a href="/reading-notes/cqNotes/DataScience/cq_clustering/" title="cq_clustering">     <img class="post_bg" src= "data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" data-lazy-src="/reading-notes/default_cover/leaves-4754980_1920.jpg" onerror="this.onerror=null;this.src='/reading-notes/img/404.jpg'" alt="cq_clustering"></a></div><div class="recent-post-info"><a class="article-title" href="/reading-notes/cqNotes/DataScience/cq_clustering/" title="cq_clustering">cq_clustering</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time datetime="2020-12-31T16:00:00.000Z" title="Created 2021-01-01 00:00:00">2021-01-01</time></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/reading-notes/tags/data-science/">data_science</a></span></div><div class="content">Notes 1 K-Means
Source: K-Means
Clustering: From A to Z. Everything you need to know about Towards Data
Science
It’s important to preprocess your data before performing K-Means. You
would have to convert your dataset into numerical values if it is not
already, so that calculations can be performed. Also, applying feature
reduction techniques would speed up the process, and also improve the
results. These steps are important to follow because K-Means is
sensitive to outliers, just like every othe ...</div></div></div><div class="recent-post-item"><div class="post_cover left_radius"><a href="/reading-notes/cqNotes/DataScience/cq_covariance/" title="cq_covariance">     <img class="post_bg" src= "data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" data-lazy-src="/reading-notes/default_cover/circles-5444818_1280.png" onerror="this.onerror=null;this.src='/reading-notes/img/404.jpg'" alt="cq_covariance"></a></div><div class="recent-post-info"><a class="article-title" href="/reading-notes/cqNotes/DataScience/cq_covariance/" title="cq_covariance">cq_covariance</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time datetime="2020-12-31T16:00:00.000Z" title="Created 2021-01-01 00:00:00">2021-01-01</time></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/reading-notes/tags/data-science/">data_science</a></span></div><div class="content">Note 1
Covariance Matrix
While we introduced matrices as something that transformed one set of
vectors into another, another way to think about them is as a
description of data that captures the forces at work upon it, the forces
by which two variables might relate to each other as expressed by their
variance and covariance.
Imagine that we compose a square matrix of numbers that describe the
variance of the data, and the covariance among variables. This is the
covariance matrix. It is an empiri ...</div></div></div><div class="recent-post-item"><div class="post_cover right_radius"><a href="/reading-notes/cqNotes/DataScience/cq_clustering_slides/" title="cq_clustering_slides">     <img class="post_bg" src= "data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" data-lazy-src="/reading-notes/default_cover/reading-7229927_1280.jpg" onerror="this.onerror=null;this.src='/reading-notes/img/404.jpg'" alt="cq_clustering_slides"></a></div><div class="recent-post-info"><a class="article-title" href="/reading-notes/cqNotes/DataScience/cq_clustering_slides/" title="cq_clustering_slides">cq_clustering_slides</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time datetime="2020-12-31T16:00:00.000Z" title="Created 2021-01-01 00:00:00">2021-01-01</time></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/reading-notes/tags/data-science/">data_science</a></span></div><div class="content">Data Mining Lecture Slides





 


Specify K clusters. Each cluster is associated with 1 centroid. Now
randomly assign K centroids.
Now for each point in the dataset, we compute a distance measure from
this point to all of the K centroids, then we move this point to the
closest centroid.
Once we repeat this for all points in the dataset, we reorganize the
points and now al the points belong to certain centroid. In total we
still have K clusters, just with different points in each cluster.
Now f ...</div></div></div><div class="recent-post-item"><div class="post_cover left_radius"><a href="/reading-notes/cqNotes/DataScience/cq_data_science/" title="cq_data_science">     <img class="post_bg" src= "data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" data-lazy-src="/reading-notes/default_cover/abstract-1264071.svg" onerror="this.onerror=null;this.src='/reading-notes/img/404.jpg'" alt="cq_data_science"></a></div><div class="recent-post-info"><a class="article-title" href="/reading-notes/cqNotes/DataScience/cq_data_science/" title="cq_data_science">cq_data_science</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time datetime="2020-12-31T16:00:00.000Z" title="Created 2021-01-01 00:00:00">2021-01-01</time></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/reading-notes/tags/data-science/">data_science</a></span></div><div class="content">
[TOC]
Data Mining Intro
What is Data Mining
Data mining tasks.
Data
Types of Data
Data Preprocessing
Measures of Similarity
and Dissimilarity
Classification
Intro
What is Classification
Given a collection of records (training set)

–Each record is by characterized by a tuple
(x,), where
x is the attribute set and  is the class label

x: attribute, predictor, independent variable,
input
: class, response, dependent
variable, output


Task:

Learn a model that maps each attribute set x into
one o ...</div></div></div><div class="recent-post-item"><div class="post_cover right_radius"><a href="/reading-notes/cqNotes/DataScience/cq_decision_tree/" title="cq_decision_tree">     <img class="post_bg" src= "data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" data-lazy-src="/reading-notes/default_cover/rainbow-5324147_1280.jpg" onerror="this.onerror=null;this.src='/reading-notes/img/404.jpg'" alt="cq_decision_tree"></a></div><div class="recent-post-info"><a class="article-title" href="/reading-notes/cqNotes/DataScience/cq_decision_tree/" title="cq_decision_tree">cq_decision_tree</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time datetime="2020-12-31T16:00:00.000Z" title="Created 2021-01-01 00:00:00">2021-01-01</time></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/reading-notes/tags/data-science/">data_science</a></span></div><div class="content">Decision Tree Classification
Here’s a step by step example: rc_decision_tree_classification_example.

Data Mining Class Slides

{width=49%} | {width=49%}

There are many decision tree induction algorithms, e.g., Hunt’s
Algorithm (one of the earliest), CART, ID3, C4.5, SLIQ, SPRINT, etc.
ID3 uses a top-down greedy approach to build a decision tree. Simply
put, in a top-down approach we start building the tree from the top and,
at each iteration, we select the best feature at the present stage to
 ...</div></div></div><div class="recent-post-item"><div class="post_cover left_radius"><a href="/reading-notes/cqNotes/DataScience/cq_dim_reduction/" title="cq_dim_reduction">     <img class="post_bg" src= "data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" data-lazy-src="/reading-notes/default_cover/microsoft-edge-mt4xBHKxFH4-unsplash.jpg" onerror="this.onerror=null;this.src='/reading-notes/img/404.jpg'" alt="cq_dim_reduction"></a></div><div class="recent-post-info"><a class="article-title" href="/reading-notes/cqNotes/DataScience/cq_dim_reduction/" title="cq_dim_reduction">cq_dim_reduction</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time datetime="2020-12-31T16:00:00.000Z" title="Created 2021-01-01 00:00:00">2021-01-01</time></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/reading-notes/tags/data-science/">data_science</a></span></div><div class="content">Note 1
Source: In-Depth:
Manifold Learning Python Data Science Handbook
We have seen how principal component analysis (PCA) can be used in
the dimensionality reduction task—reducing the number of features of a
dataset while maintaining the essential relationships between the
points. While PCA is flexible, fast, and easily interpretable, it does
not perform so well when there are nonlinear relationships
within the data; we will see some examples of these below.
We have seen how principal componen ...</div></div></div><div class="recent-post-item"><div class="post_cover right_radius"><a href="/reading-notes/cqNotes/DataScience/cq_ensemble_methods/" title="cq_ensemble_methods">     <img class="post_bg" src= "data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" data-lazy-src="/reading-notes/default_cover/trees-6207925_1920.jpg" onerror="this.onerror=null;this.src='/reading-notes/img/404.jpg'" alt="cq_ensemble_methods"></a></div><div class="recent-post-info"><a class="article-title" href="/reading-notes/cqNotes/DataScience/cq_ensemble_methods/" title="cq_ensemble_methods">cq_ensemble_methods</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time datetime="2020-12-31T16:00:00.000Z" title="Created 2021-01-01 00:00:00">2021-01-01</time></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/reading-notes/tags/data-science/">data_science</a></span></div><div class="content">Notes 1
Some notes from this post: Types
of Ensemble methods in Machine learning | by Anju Rajbangshi | Towards
Data Science
In simple English, ensemble refers to a group of items. For e.g: a
group of ministers, a group of dancers etc. (In machine learning) An
ensemble method is a technique which uses multiple independent similar
or different models/weak learners to derive an output or make some
predictions.
An ensemble can also be built with a combination of different
models like random forest, ...</div></div></div><div class="recent-post-item"><div class="post_cover left_radius"><a href="/reading-notes/cqNotes/DataScience/cq_knn/" title="cq_knn">     <img class="post_bg" src= "data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" data-lazy-src="/reading-notes/default_cover/circles-5444818_1280.png" onerror="this.onerror=null;this.src='/reading-notes/img/404.jpg'" alt="cq_knn"></a></div><div class="recent-post-info"><a class="article-title" href="/reading-notes/cqNotes/DataScience/cq_knn/" title="cq_knn">cq_knn</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time datetime="2020-12-31T16:00:00.000Z" title="Created 2021-01-01 00:00:00">2021-01-01</time></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/reading-notes/tags/data-science/">data_science</a></span></div><div class="content">Overview
KNN can be used for both classification and regression predictive
problems. However, it is more widely used in classification problems in
the industry.
Code example with grid cv search: K-Nearest
Neighbors Explained with Python Examples - Data Analytics
The KNN Algorithm from Machine
Learning Basics with the K-Nearest Neighbors Algorithm | by Onel
Harrison | Towards Data Science

Load the data
Initialize K to your chosen number of neighbors
For each example in the data

Calculate the di ...</div></div></div><div class="recent-post-item"><div class="post_cover right_radius"><a href="/reading-notes/cqNotes/DataScience/cq_naive_bayes/" title="cq_naive_bayes">     <img class="post_bg" src= "data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" data-lazy-src="/reading-notes/default_cover/river-6968614.svg" onerror="this.onerror=null;this.src='/reading-notes/img/404.jpg'" alt="cq_naive_bayes"></a></div><div class="recent-post-info"><a class="article-title" href="/reading-notes/cqNotes/DataScience/cq_naive_bayes/" title="cq_naive_bayes">cq_naive_bayes</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time datetime="2020-12-31T16:00:00.000Z" title="Created 2021-01-01 00:00:00">2021-01-01</time></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/reading-notes/tags/data-science/">data_science</a></span></div><div class="content">Data Mining Slides








  
   
   
 
Example 1
This example is from: Learn
Naive Bayes Algorithm | Naive Bayes Classifier Examples
It is a classification
technique based on Bayes’ Theorem with an assumption of independence
among predictors. In simple terms, a Naive Bayes classifier assumes that
the presence of a particular feature in a class is unrelated to the
presence of any other feature.
For example, a fruit may be considered to be an apple if it is red,
round, and about 3 inches in diame ...</div></div></div><div class="recent-post-item"><div class="post_cover left_radius"><a href="/reading-notes/cqNotes/DataScience/cq_pca/" title="cq_pca">     <img class="post_bg" src= "data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" data-lazy-src="/reading-notes/default_cover/circles-5444818_1280.png" onerror="this.onerror=null;this.src='/reading-notes/img/404.jpg'" alt="cq_pca"></a></div><div class="recent-post-info"><a class="article-title" href="/reading-notes/cqNotes/DataScience/cq_pca/" title="cq_pca">cq_pca</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time datetime="2020-12-31T16:00:00.000Z" title="Created 2021-01-01 00:00:00">2021-01-01</time></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/reading-notes/tags/data-science/">data_science</a></span></div><div class="content">Note 1
Variance is the measure of the data’s spread. If I take a team of Dutch
basketball players and measure their height, those measurements
won’t have a lot of variance. They’ll all be grouped above six feet. But
if I throw the Dutch basketball team into a classroom of psychotic
kindergartners, then the combined group’s height measurements will have
a lot of variance. Variance is the spread, or the amount of difference
that data expresses.
Variance is simply standard deviation squared.

PCA a ...</div></div></div><div class="recent-post-item"><div class="post_cover right_radius"><a href="/reading-notes/cqNotes/DataScience/cq_performance_metrics/" title="cq_performance_metrics">     <img class="post_bg" src= "data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" data-lazy-src="/reading-notes/default_cover/toucan-4185361_1280.jpg" onerror="this.onerror=null;this.src='/reading-notes/img/404.jpg'" alt="cq_performance_metrics"></a></div><div class="recent-post-info"><a class="article-title" href="/reading-notes/cqNotes/DataScience/cq_performance_metrics/" title="cq_performance_metrics">cq_performance_metrics</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time datetime="2020-12-31T16:00:00.000Z" title="Created 2021-01-01 00:00:00">2021-01-01</time></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/reading-notes/tags/data-science/">data_science</a></span></div><div class="content">Overview
Sources:

20
Popular Machine Learning Metrics. Part 1: Classification &amp;
Regression Evaluation Metrics by Shervin Minaee Towards Data
Science
An
Overview of Performance Evaluation Metrics of Machine
Learning(Classification) Algorithms in Python Towards Data
Science
Different
metrics to evaluate the performance of a Machine Learning model
Performance
Metrics for Machine Learning Models Analytics Vidhya
Performance
Metrics in ML Part3 Clustering Towards Data Science
Performance
Metrics ...</div></div></div><div class="recent-post-item"><div class="post_cover left_radius"><a href="/reading-notes/cqNotes/DataScience/cq_random_forest/" title="cq_random_forest">     <img class="post_bg" src= "data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" data-lazy-src="/reading-notes/default_cover/trees-6207925_1920.jpg" onerror="this.onerror=null;this.src='/reading-notes/img/404.jpg'" alt="cq_random_forest"></a></div><div class="recent-post-info"><a class="article-title" href="/reading-notes/cqNotes/DataScience/cq_random_forest/" title="cq_random_forest">cq_random_forest</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time datetime="2020-12-31T16:00:00.000Z" title="Created 2021-01-01 00:00:00">2021-01-01</time></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/reading-notes/tags/data-science/">data_science</a></span></div><div class="content">Overview
This algorithm specification is from the book: Introduction
to Algorithms for Data Mining and Machine Learning.
The main idea of the random forest classifier to construct multiple
decision trees randomly using sampling with replacement, and the final
decisions will be based on a rule, often in terms of a voting system of
the ensemble of the decision trees. In essence, the random forest
classifier is an ensemble method or ensemble-based decision-tree
learning with the aim to improve accu ...</div></div></div><div class="recent-post-item"><div class="post_cover right_radius"><a href="/reading-notes/cqNotes/DataScience/cq_regularization/" title="cq_regularization">     <img class="post_bg" src= "data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" data-lazy-src="/reading-notes/default_cover/circles-5444818_1280.png" onerror="this.onerror=null;this.src='/reading-notes/img/404.jpg'" alt="cq_regularization"></a></div><div class="recent-post-info"><a class="article-title" href="/reading-notes/cqNotes/DataScience/cq_regularization/" title="cq_regularization">cq_regularization</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time datetime="2020-12-31T16:00:00.000Z" title="Created 2021-01-01 00:00:00">2021-01-01</time></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/reading-notes/tags/data-science/">data_science</a></span></div><div class="content">L1 and L2 Regularization
Source: L1
and L2 Regularization Methods. Machine Learning | by Anuja Nagpal |
Towards Data Science
L1
vs L2 Regularization: The intuitive difference | by Dhaval Taunk |
Analytics Vidhya | Medium
A regression model that uses L1 regularization technique is called
Lasso Regression and model which uses L2 is
called Ridge Regression. The key
difference between these two is the penalty term.
A regression model that uses L1 regularization technique is called
Lasso Regression a ...</div></div></div><div class="recent-post-item"><div class="post_cover left_radius"><a href="/reading-notes/cqNotes/DataScience/cq_svd/" title="cq_svd">     <img class="post_bg" src= "data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" data-lazy-src="/reading-notes/default_cover/reading-7229927_1280.jpg" onerror="this.onerror=null;this.src='/reading-notes/img/404.jpg'" alt="cq_svd"></a></div><div class="recent-post-info"><a class="article-title" href="/reading-notes/cqNotes/DataScience/cq_svd/" title="cq_svd">cq_svd</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time datetime="2020-12-31T16:00:00.000Z" title="Created 2021-01-01 00:00:00">2021-01-01</time></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/reading-notes/tags/data-science/">data_science</a></span></div><div class="content">In linear
algebra, the singular value decomposition
(SVD) is a factorization
of a real or complex matrix. It
generalizes the eigendecomposition
of a square normal
matrix with an orthonormal eigenbasis to any  matrix.
</div></div></div><div class="recent-post-item"><div class="post_cover right_radius"><a href="/reading-notes/cqNotes/DataScience/cq_svm/" title="cq_svm">     <img class="post_bg" src= "data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" data-lazy-src="/reading-notes/default_cover/river-6968614.svg" onerror="this.onerror=null;this.src='/reading-notes/img/404.jpg'" alt="cq_svm"></a></div><div class="recent-post-info"><a class="article-title" href="/reading-notes/cqNotes/DataScience/cq_svm/" title="cq_svm">cq_svm</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time datetime="2020-12-31T16:00:00.000Z" title="Created 2021-01-01 00:00:00">2021-01-01</time></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/reading-notes/tags/data-science/">data_science</a></span></div><div class="content">Vector Prerequisite Review
See this note for detail: Vector
Basics Notes.
Vector basics

We can think of all these geometric vectors as
representations of the algebraic vector ​​. The particular
representation 
From the origin to the point 
Is called the position vector of the point .










Projections



{width=32%} {width=32%} {width=32%}

Notice that the vector projection is the scalar projection times the
unit vector int he direction of ​.

The distance between a
point and a line
A vecto ...</div></div></div><div class="recent-post-item"><div class="post_cover left_radius"><a href="/reading-notes/cqNotes/LinearAlgebra/cq_linear_algebra1/" title="Linear Algebra (3Blue1Brown) Notes (1)">     <img class="post_bg" src= "data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" data-lazy-src="/reading-notes/default_cover/reading-7229927_1280.jpg" onerror="this.onerror=null;this.src='/reading-notes/img/404.jpg'" alt="Linear Algebra (3Blue1Brown) Notes (1)"></a></div><div class="recent-post-info"><a class="article-title" href="/reading-notes/cqNotes/LinearAlgebra/cq_linear_algebra1/" title="Linear Algebra (3Blue1Brown) Notes (1)">Linear Algebra (3Blue1Brown) Notes (1)</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time datetime="2020-12-31T16:00:00.000Z" title="Created 2021-01-01 00:00:00">2021-01-01</time></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/reading-notes/tags/ml-math/">ml_math</a><span class="article-meta__link">•</span><a class="article-meta__tags" href="/reading-notes/tags/lin-algebra/">lin_algebra</a></span></div><div class="content">3Blue1Brown Video Notes
[TOC]
Source: Chapter
1, Essence of linear algebra - YouTube
Chapter 1 Vectors
Three perspectives.
Physical’s students: vectors are arrows pointing in space, defined by
its length and the direction it’s pointing, as long as these two
properties are the same, you can move them around in space and it’ll be
the same vector.
CS students: ordered lists of numbers. Order matters.

Math students: Generalized.
[3,2]: move right (or left if negative)(along a specific
axis/dimensio ...</div></div></div><div class="recent-post-item"><div class="post_cover right_radius"><a href="/reading-notes/cqNotes/LinearAlgebra/cq_linear_algebra2/" title="Linear Algebra Notes (2)">     <img class="post_bg" src= "data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" data-lazy-src="/reading-notes/default_cover/museum-5431661_1280.jpg" onerror="this.onerror=null;this.src='/reading-notes/img/404.jpg'" alt="Linear Algebra Notes (2)"></a></div><div class="recent-post-info"><a class="article-title" href="/reading-notes/cqNotes/LinearAlgebra/cq_linear_algebra2/" title="Linear Algebra Notes (2)">Linear Algebra Notes (2)</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time datetime="2020-12-31T16:00:00.000Z" title="Created 2021-01-01 00:00:00">2021-01-01</time></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/reading-notes/tags/ml-math/">ml_math</a><span class="article-meta__link">•</span><a class="article-meta__tags" href="/reading-notes/tags/lin-algebra/">lin_algebra</a></span></div><div class="content">A simple example is that an eigenvector does not change
direction in a transformation:

For a square matrix A, an Eigenvector and Eigenvalue
make this equation true:


Source: A Beginner's
Guide to Eigenvectors, Eigenvalues, PCA, Covariance and Entropy
The eigen in eigenvector comes from German, and it means
something like “very own.” For example, in German, “mein eigenes Auto”
means “my very own car.” So eigen denotes a special relationship between
two things. Something particular, characterist ...</div></div></div><div class="recent-post-item"><div class="post_cover left_radius"><a href="/reading-notes/cqNotes/ML/cq_linear_regr/" title="cq_linear_regr">     <img class="post_bg" src= "data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" data-lazy-src="/reading-notes/default_cover/typewriter-801921_1920.jpg" onerror="this.onerror=null;this.src='/reading-notes/img/404.jpg'" alt="cq_linear_regr"></a></div><div class="recent-post-info"><a class="article-title" href="/reading-notes/cqNotes/ML/cq_linear_regr/" title="cq_linear_regr">cq_linear_regr</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time datetime="2020-12-31T16:00:00.000Z" title="Created 2021-01-01 00:00:00">2021-01-01</time></span></div><div class="content">Linear Regression
This is from 4.1
Linear Regression | Interpretable Machine Learning.
A linear regression model predicts the target as a weighted sum of
the feature inputs. Linear models can be used to model the dependence of
a regression target  on some
features . The learned
relationships are linear and can be written for a single instance  as follows: 
The predicted outcome of an instance is a weighted sum of its  features. The betas  represent the learned feature
weights or coefficients. Th ...</div></div></div><div class="recent-post-item"><div class="post_cover right_radius"><a href="/reading-notes/cqNotes/ML/cq_logistic_regr/" title="cq_logistic_regr">     <img class="post_bg" src= "data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" data-lazy-src="/reading-notes/default_cover/gamer-6022003.svg" onerror="this.onerror=null;this.src='/reading-notes/img/404.jpg'" alt="cq_logistic_regr"></a></div><div class="recent-post-info"><a class="article-title" href="/reading-notes/cqNotes/ML/cq_logistic_regr/" title="cq_logistic_regr">cq_logistic_regr</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time datetime="2020-12-31T16:00:00.000Z" title="Created 2021-01-01 00:00:00">2021-01-01</time></span></div><div class="content">Overview
Some sources: Intro
to Statistical Learning Logistic Regression Section
An online book: 4.2
Logistic Regression | Interpretable Machine Learning
The section on softmax regression and cross entropy: Dive
Into Deep Learning Section
Logistic regression models the probabilities for classification
problems with two possible outcomes. It's an extension of the linear
regression model for classification problems.
Intro 1
Source: Intro
to Statistical Learning Logistic Regression Section
Binary L ...</div></div></div><div class="recent-post-item"><div class="post_cover left_radius"><a href="/reading-notes/cqNotes/ML/cq_loss_function/" title="cq_loss_function">     <img class="post_bg" src= "data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" data-lazy-src="/reading-notes/default_cover/leaves-4754980_1920.jpg" onerror="this.onerror=null;this.src='/reading-notes/img/404.jpg'" alt="cq_loss_function"></a></div><div class="recent-post-info"><a class="article-title" href="/reading-notes/cqNotes/ML/cq_loss_function/" title="cq_loss_function">cq_loss_function</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time datetime="2020-12-31T16:00:00.000Z" title="Created 2021-01-01 00:00:00">2021-01-01</time></span></div><div class="content">Cross Entropy Loss Function
There are two tutorials for the following information: 1. rc_cross
entropy_A Friendly Introduction to Cross Entropy Loss and 2. rc_cross
entropy_Medium.
When we develop a model for probabilistic classification, we aim to
map the models inputs to probabilistic predictions, and we
often train our model by incrementally adjusting the models
parameters so that our predictions get closer and closer to
ground-truth probabilities. For example, the ground-truth class
prbabili ...</div></div></div><nav id="pagination"><div class="pagination"><a class="extend prev" rel="prev" href="/reading-notes/page/2/#content-inner"><i class="fas fa-chevron-left fa-fw"></i></a><a class="page-number" href="/reading-notes/">1</a><a class="page-number" href="/reading-notes/page/2/#content-inner">2</a><span class="page-number current">3</span><a class="page-number" href="/reading-notes/page/4/#content-inner">4</a><a class="page-number" href="/reading-notes/page/5/#content-inner">5</a><a class="extend next" rel="next" href="/reading-notes/page/4/#content-inner"><i class="fas fa-chevron-right fa-fw"></i></a></div></nav></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src= "data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" data-lazy-src="https://i.loli.net/2021/02/24/5O1day2nriDzjSu.png" onerror="this.onerror=null;this.src='/reading-notes/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name"></div><div class="author-info__description">Temporary reading notes and testing the Hexo framework. Not for public use.</div></div><div class="card-info-data"><div class="card-info-data-item is-center"><a href="/reading-notes/archives/"><div class="headline">Articles</div><div class="length-num">102</div></a></div><div class="card-info-data-item is-center"><a href="/reading-notes/tags/"><div class="headline">Tags</div><div class="length-num">22</div></a></div><div class="card-info-data-item is-center"><a href="/reading-notes/categories/"><div class="headline">Categories</div><div class="length-num">12</div></a></div></div><div class="card-info-social-icons is-center"><a class="social-icon" href="mailto:gold.radio_00@icloud.com" rel="external nofollow noreferrer" target="_blank" title="Email"><i class="fas fa-envelope"></i></a></div></div><div class="sticky_layout"><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>Recent Post</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/reading-notes/cqNotes/ObsidianNotes/LogicFallacies/%E5%85%B3%E8%81%94%E6%80%A7%E8%B0%AC%E8%AF%AF01/" title="关联性逻辑谬误 （一）"><img src= "data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" data-lazy-src="/reading-notes/default_cover/science-1182713_1920.jpg" onerror="this.onerror=null;this.src='/reading-notes/img/404.jpg'" alt="关联性逻辑谬误 （一）"/></a><div class="content"><a class="title" href="/reading-notes/cqNotes/ObsidianNotes/LogicFallacies/%E5%85%B3%E8%81%94%E6%80%A7%E8%B0%AC%E8%AF%AF01/" title="关联性逻辑谬误 （一）">关联性逻辑谬误 （一）</a><time datetime="2022-05-10T03:34:56.000Z" title="Created 2022-05-10 11:34:56">2022-05-10</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/reading-notes/cqNotes/ObsidianNotes/LogicFallacies/%E4%B8%A4%E9%9A%BE%E8%B0%AC%E8%AF%AF/" title="两难谬误"><img src= "data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" data-lazy-src="/reading-notes/default_cover/gamer-6022003.svg" onerror="this.onerror=null;this.src='/reading-notes/img/404.jpg'" alt="两难谬误"/></a><div class="content"><a class="title" href="/reading-notes/cqNotes/ObsidianNotes/LogicFallacies/%E4%B8%A4%E9%9A%BE%E8%B0%AC%E8%AF%AF/" title="两难谬误">两难谬误</a><time datetime="2022-05-09T08:42:59.000Z" title="Created 2022-05-09 16:42:59">2022-05-09</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/reading-notes/cqNotes/ObsidianNotes/LogicFallacies/%E9%9D%9E%E7%9C%9F%E6%AD%A3%E8%8B%8F%E6%A0%BC%E5%85%B0%E4%BA%BA%E8%B0%AC%E8%AF%AF/" title="非真正苏格兰人谬误"><img src= "data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" data-lazy-src="/reading-notes/default_cover/microsoft-edge-mt4xBHKxFH4-unsplash.jpg" onerror="this.onerror=null;this.src='/reading-notes/img/404.jpg'" alt="非真正苏格兰人谬误"/></a><div class="content"><a class="title" href="/reading-notes/cqNotes/ObsidianNotes/LogicFallacies/%E9%9D%9E%E7%9C%9F%E6%AD%A3%E8%8B%8F%E6%A0%BC%E5%85%B0%E4%BA%BA%E8%B0%AC%E8%AF%AF/" title="非真正苏格兰人谬误">非真正苏格兰人谬误</a><time datetime="2022-05-08T02:26:16.000Z" title="Created 2022-05-08 10:26:16">2022-05-08</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/reading-notes/cqNotes/ObsidianNotes/LogicFallacies/%E5%BC%B1%E5%BD%92%E7%BA%B3%E8%B0%AC%E8%AF%AF01/" title="弱归纳谬误（一）"><img src= "data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" data-lazy-src="/reading-notes/default_cover/pi-1453836_1280.jpg" onerror="this.onerror=null;this.src='/reading-notes/img/404.jpg'" alt="弱归纳谬误（一）"/></a><div class="content"><a class="title" href="/reading-notes/cqNotes/ObsidianNotes/LogicFallacies/%E5%BC%B1%E5%BD%92%E7%BA%B3%E8%B0%AC%E8%AF%AF01/" title="弱归纳谬误（一）">弱归纳谬误（一）</a><time datetime="2022-05-08T01:48:21.000Z" title="Created 2022-05-08 09:48:21">2022-05-08</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/reading-notes/cqNotes/ObsidianNotes/LogicFallacies/%E5%81%87%E5%9B%A0%E6%9E%9C%E8%B0%AC%E8%AF%AF/" title="假因果谬误"><img src= "data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" data-lazy-src="/reading-notes/default_cover/trees-6207925_1920.jpg" onerror="this.onerror=null;this.src='/reading-notes/img/404.jpg'" alt="假因果谬误"/></a><div class="content"><a class="title" href="/reading-notes/cqNotes/ObsidianNotes/LogicFallacies/%E5%81%87%E5%9B%A0%E6%9E%9C%E8%B0%AC%E8%AF%AF/" title="假因果谬误">假因果谬误</a><time datetime="2022-05-07T10:03:52.000Z" title="Created 2022-05-07 18:03:52">2022-05-07</time></div></div></div></div><div class="card-widget card-categories"><div class="item-headline">
            <i class="fas fa-folder-open"></i>
            <span>Categories</span>
            <a class="card-more-btn" href="/reading-notes/categories/" title="More">
    <i class="fas fa-angle-right"></i></a>
            </div>
            <ul class="card-category-list" id="aside-cat-list">
            <li class="card-category-list-item "><a class="card-category-list-link" href="/reading-notes/categories/Algorithms/"><span class="card-category-list-name">Algorithms</span><span class="card-category-list-count">1</span></a><ul class="card-category-list child"><li class="card-category-list-item "><a class="card-category-list-link" href="/reading-notes/categories/Algorithms/DataStructure/"><span class="card-category-list-name">DataStructure</span><span class="card-category-list-count">1</span></a></li></ul></li><li class="card-category-list-item "><a class="card-category-list-link" href="/reading-notes/categories/CriticalThinking/"><span class="card-category-list-name">CriticalThinking</span><span class="card-category-list-count">17</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/reading-notes/categories/ML/"><span class="card-category-list-name">ML</span><span class="card-category-list-count">3</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/reading-notes/categories/MLFramework/"><span class="card-category-list-name">MLFramework</span><span class="card-category-list-count">5</span></a><ul class="card-category-list child"><li class="card-category-list-item "><a class="card-category-list-link" href="/reading-notes/categories/MLFramework/Pytorch/"><span class="card-category-list-name">Pytorch</span><span class="card-category-list-count">5</span></a></li></ul></li><li class="card-category-list-item "><a class="card-category-list-link" href="/reading-notes/categories/MLMath/"><span class="card-category-list-name">MLMath</span><span class="card-category-list-count">3</span></a><ul class="card-category-list child"><li class="card-category-list-item "><a class="card-category-list-link" href="/reading-notes/categories/MLMath/Calculus/"><span class="card-category-list-name">Calculus</span><span class="card-category-list-count">1</span></a></li></ul></li>
            </ul></div><div class="card-widget card-tags"><div class="item-headline"><i class="fas fa-tags"></i><span>Tags</span></div><div class="card-tag-cloud"><a href="/reading-notes/tags/software-dev/" style="font-size: 1.45em; color: rgb(87, 140, 195)">software_dev</a><a href="/reading-notes/tags/java/" style="font-size: 1.26em; color: rgb(50, 166, 179)">java</a><a href="/reading-notes/tags/sample/" style="font-size: 1.34em; color: rgb(103, 55, 69)">sample</a><a href="/reading-notes/tags/docker/" style="font-size: 1.15em; color: rgb(66, 164, 62)">docker</a><a href="/reading-notes/tags/en/" style="font-size: 1.3em; color: rgb(37, 159, 123)">en</a><a href="/reading-notes/tags/spring/" style="font-size: 1.3em; color: rgb(41, 104, 1)">spring</a><a href="/reading-notes/tags/data-science/" style="font-size: 1.38em; color: rgb(3, 150, 186)">data_science</a><a href="/reading-notes/tags/ml-math/" style="font-size: 1.22em; color: rgb(113, 126, 2)">ml_math</a><a href="/reading-notes/tags/lin-algebra/" style="font-size: 1.19em; color: rgb(139, 71, 59)">lin_algebra</a><a href="/reading-notes/tags/info-theory/" style="font-size: 1.15em; color: rgb(168, 20, 178)">info_theory</a><a href="/reading-notes/tags/ml-cnn/" style="font-size: 1.15em; color: rgb(154, 65, 40)">ml_cnn</a><a href="/reading-notes/tags/calculus/" style="font-size: 1.15em; color: rgb(130, 106, 84)">calculus</a><a href="/reading-notes/tags/dev-tool/" style="font-size: 1.15em; color: rgb(43, 23, 147)">dev_tool</a><a href="/reading-notes/tags/python/" style="font-size: 1.15em; color: rgb(188, 37, 121)">python</a><a href="/reading-notes/tags/pytorch/" style="font-size: 1.26em; color: rgb(82, 124, 106)">pytorch</a><a href="/reading-notes/tags/criticalThinking/" style="font-size: 1.41em; color: rgb(175, 182, 46)">criticalThinking</a><a href="/reading-notes/tags/logicFallacy/" style="font-size: 1.41em; color: rgb(67, 121, 128)">logicFallacy</a><a href="/reading-notes/tags/pd-ml/" style="font-size: 1.15em; color: rgb(90, 164, 95)">pd_ml</a><a href="/reading-notes/tags/algo/" style="font-size: 1.15em; color: rgb(114, 2, 114)">algo</a><a href="/reading-notes/tags/data-structure/" style="font-size: 1.15em; color: rgb(99, 107, 42)">data-structure</a><a href="/reading-notes/tags/reading-notes/" style="font-size: 1.15em; color: rgb(196, 31, 154)">reading_notes</a><a href="/reading-notes/tags/dev-project/" style="font-size: 1.15em; color: rgb(65, 131, 14)">dev_project</a></div></div><div class="card-widget card-webinfo"><div class="item-headline"><i class="fas fa-chart-line"></i><span>Info</span></div><div class="webinfo"><div class="webinfo-item"><div class="item-name">Article :</div><div class="item-count">102</div></div><div class="webinfo-item"><div class="item-name">Total Count :</div><div class="item-count">185.7k</div></div><div class="webinfo-item"><div class="item-name">Last Push :</div><div class="item-count" id="last-push-date" data-lastPushDate="2022-06-21T04:00:03.296Z"></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="font-plus" type="button" title="Increase font size"><i class="fas fa-plus"></i></button><button id="font-minus" type="button" title="Decrease font size"><i class="fas fa-minus"></i></button><button id="darkmode" type="button" title="Switch Between Light And Dark Mode"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="Toggle between single-column and double-column"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="Setting"><i class="fas fa-cog fa-spin"></i></button><button id="go-up" type="button" title="Back To Top"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><div class="search-dialog__title" id="local-search-title">Local search</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="Search for Posts" type="text"/></div></div></div><hr/><div id="local-search-results"></div><span class="search-close-button"><i class="fas fa-times"></i></span></div><div id="search-mask"></div></div><div><script src="/reading-notes/js/utils.js"></script><script src="/reading-notes/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/vanilla-lazyload/dist/lazyload.iife.min.js"></script><script>function panguFn () {
  if (typeof pangu === 'object') pangu.autoSpacingPage()
  else {
    getScript('https://cdn.jsdelivr.net/npm/pangu/dist/browser/pangu.min.js')
      .then(() => {
        pangu.autoSpacingPage()
      })
  }
}

function panguInit () {
  if (false){
    GLOBAL_CONFIG_SITE.isPost && panguFn()
  } else {
    panguFn()
  }
}

document.addEventListener('DOMContentLoaded', panguInit)</script><script src="/reading-notes/js/search/local-search.js"></script><div class="js-pjax"><script>if (document.getElementsByClassName('mermaid').length) {
  if (window.mermaidJsLoad) mermaid.init()
  else {
    getScript('https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js').then(() => {
      window.mermaidJsLoad = true
      mermaid.initialize({
        theme: 'default',
      })
      false && mermaid.init()
    })
  }
}</script></div></div><!-- hexo injector body_end start --><script async src="//at.alicdn.com/t/font_2032782_8d5kxvn09md.js"></script><!-- hexo injector body_end end --></body></html>